{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aS-4cLk5I5TK",
        "Dn7nW9ZS1ujP",
        "Nk1Ekoj3zmH0",
        "dQu_LV6i3TgM",
        "AR_f2mTD3uHY"
      ],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AICUP_影像資料生成競賽"
      ],
      "metadata": {
        "id": "_zVdrLoWd2Un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**各項程式碼有路徑的皆有含路徑說明，請注意資料路徑**"
      ],
      "metadata": {
        "id": "WhGKNUZCzn3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 環境配置"
      ],
      "metadata": {
        "id": "aS-4cLk5I5TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 連接雲端\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7SNzgPMKd62e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c7849ba8-0a7f-4899-c48c-8e3b8c2e71f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 將程式碼clone至colab檔案處\n",
        "\n",
        "! git clone https://github.com/Tingouoww/aicup2024.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KratNCvvRnWC",
        "outputId": "8f470f8b-6a42-4d38-c7d2-864f0e8a97ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'aicup2024'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 101 (delta 28), reused 89 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (101/101), 632.11 KiB | 15.05 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 更改當前工作目錄\n",
        "import os\n",
        "os.chdir('/content/aicup2024')"
      ],
      "metadata": {
        "id": "wpIE0dusd_u6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 安裝所需套件\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "z2GjW0tjI1z_",
        "outputId": "24e283b5-7159-4316-f7ac-68ded5868cfa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.18.0+cu121)\n",
            "Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n",
            "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb (from -r requirements.txt (line 5))\n",
            "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.16.0)\n",
            "Collecting jsonpatch (from visdom>=0.1.8.8->-r requirements.txt (line 4))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (6.0.1)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading sentry_sdk-2.4.0-py2.py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.2/289.2 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb->-r requirements.txt (line 5))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 5)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (2.1.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4))\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: visdom\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408195 sha256=0beaf0328136290dd1e8a8a7cd6bdbb2e1730b365c24337d14bf431c5a719eb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
            "Successfully built visdom\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jsonpointer, dominate, docker-pycreds, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jsonpatch, gitdb, visdom, nvidia-cusolver-cu12, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 dominate-2.9.1 gitdb-4.0.11 gitpython-3.1.43 jsonpatch-1.33 jsonpointer-2.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentry-sdk-2.4.0 setproctitle-1.3.3 smmap-5.0.1 visdom-0.2.4 wandb-0.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 資料前處理\n",
        "\n",
        "- 圖片放大及填充\n",
        "- label img 與 img 合併\n",
        "- 分割道路與河流圖\n",
        "- 分割驗證集與訓練集\n",
        "\n"
      ],
      "metadata": {
        "id": "GdsZzz5YJXy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 圖片放大與填充\n",
        "\n",
        "1. 將原始圖片(428*240)放大至長為512像素，寬依此比例放大\n",
        "2. 未達512 * 512的部分填充成白色\n",
        "\n",
        "- label_img與img皆要完成"
      ],
      "metadata": {
        "id": "agZBRrvET4JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageOps\n",
        "\n",
        "def pad_image(input_path, output_path, target_size=(512, 512), padding_color=(255, 255, 255)):\n",
        "    \"\"\"\n",
        "    input_path: 原始圖片路徑\n",
        "    output_path: 填充後圖片的保存路徑\n",
        "    target_size: 填充目標大小(寬, 高)\n",
        "    padding_color: 填充使用顏色\n",
        "    \"\"\"\n",
        "    img = Image.open(input_path)\n",
        "    ori_size = img.size  # (width, height)\n",
        "\n",
        "    # 計算比例並調整圖片大小\n",
        "    ratio = target_size[0] / ori_size[0]\n",
        "    new_size = tuple([int(x * ratio) for x in ori_size])\n",
        "    img_resized = img.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "    # 創建新圖片進行填充\n",
        "    new_img = Image.new(\"RGB\", target_size, padding_color)\n",
        "    new_img.paste(img_resized, ((target_size[0] - new_size[0]) // 2,(target_size[1] - new_size[1]) // 2))\n",
        "\n",
        "    # 填充圖片存檔\n",
        "    new_img.save(output_path)\n",
        "\n",
        "\"\"\"\n",
        "路徑說明\n",
        "ori_path 請填入原始圖片所在資料夾之路徑\n",
        "pad_path 請填入要放置填充後圖片之路徑\n",
        "\"\"\"\n",
        "\n",
        "ori_path = '/content/drive/MyDrive/2024_AICUP/original_data/A'\n",
        "pad_path = '/content/aicup2024/padding/A'\n",
        "\n",
        "if not os.path.exists(pad_path):\n",
        "    os.makedirs(pad_path)\n",
        "\n",
        "for filename in os.listdir(ori_path):\n",
        "\n",
        "  original_path = os.path.join(ori_path, filename)\n",
        "  padded_path = os.path.join(pad_path, filename)\n",
        "  pad_image(original_path, padded_path, target_size=(512, 512))"
      ],
      "metadata": {
        "id": "zTMLkngNJZ6i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "b102390f-f2f7-4660-d2e7-a1abef0cb7c6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-f67d36e8c0fe>:16: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img_resized = img.resize(new_size, Image.ANTIALIAS)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f67d36e8c0fe>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0moriginal_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mpadded_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0mpad_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-f67d36e8c0fe>\u001b[0m in \u001b[0;36mpad_image\u001b[0;34m(input_path, output_path, target_size, padding_color)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# 填充圖片存檔\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mnew_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2431\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2432\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0m_write_multiple_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flush\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    539\u001b[0m                     \u001b[0;31m# compress to Python file-compatible object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m                         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m                         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageOps\n",
        "\n",
        "def pad_image(input_path, output_path, target_size=(512, 512), padding_color=(255, 255, 255)):\n",
        "    \"\"\"\n",
        "    input_path: 原始圖片路徑\n",
        "    output_path: 填充後圖片的保存路徑\n",
        "    target_size: 填充目標大小(寬, 高)\n",
        "    padding_color: 填充使用顏色\n",
        "    \"\"\"\n",
        "    img = Image.open(input_path)\n",
        "    ori_size = img.size  # (width, height)\n",
        "\n",
        "    # 計算比例並調整圖片大小\n",
        "    ratio = target_size[0] / ori_size[0]\n",
        "    new_size = tuple([int(x * ratio) for x in ori_size])\n",
        "    img_resized = img.resize(new_size, Image.ANTIALIAS)\n",
        "\n",
        "    # 創建新圖片進行填充\n",
        "    new_img = Image.new(\"RGB\", target_size, padding_color)\n",
        "    new_img.paste(img_resized, ((target_size[0] - new_size[0]) // 2,(target_size[1] - new_size[1]) // 2))\n",
        "\n",
        "    # 填充圖片存檔\n",
        "    new_img.save(output_path)\n",
        "\n",
        "\"\"\"\n",
        "路徑說明\n",
        "ori_path 請填入原始圖片所在資料夾之路徑\n",
        "pad_path 請填入要放置填充後圖片之路徑\n",
        "\"\"\"\n",
        "\n",
        "ori_path = '/content/drive/MyDrive/2024_AICUP/original_data/B'\n",
        "pad_path = '/content/aicup2024/padding/B'\n",
        "\n",
        "if not os.path.exists(pad_path):\n",
        "    os.makedirs(pad_path)\n",
        "\n",
        "for filename in os.listdir(ori_path):\n",
        "\n",
        "  original_path = os.path.join(ori_path, filename)\n",
        "  padded_path = os.path.join(pad_path, filename)\n",
        "  pad_image(original_path, padded_path, target_size=(512, 512))"
      ],
      "metadata": {
        "id": "Zg9SKiXo0EjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 訓練資料集之二值圖與真實圖合併"
      ],
      "metadata": {
        "id": "q1Ac9cYbVfvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練資料集二值圖與真實圖合併\n",
        "\"\"\"\n",
        "路徑說明\n",
        "--fold_A label_img_path\n",
        "--fold_B img_path\n",
        "--fold_AB after_padding_path\n",
        "\"\"\"\n",
        "\n",
        "!python datasets/combine_A_and_B.py --fold_A /content/aicup2024/padding/A --fold_B /content/aicup2024/padding/B --fold_AB /content/aicup2024/padding/AB"
      ],
      "metadata": {
        "id": "qRk_pmDCLxMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 分割河流與道路圖\n",
        "- 將河流圖與道路圖拆分到不同資料集，以便後續分開訓練"
      ],
      "metadata": {
        "id": "JwEdEK-dVmvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 分割河流與道路圖\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\"\"\"\n",
        "路徑說明\n",
        "data_dir 資料集所在路徑\n",
        "road_dir 道路資料集所要存放之路徑\n",
        "river_dir 河流資料集所要存放之路徑\n",
        "\"\"\"\n",
        "\n",
        "data_dir = '/content/aicup2024/padding/AB'\n",
        "road_dir = '/content/aicup2024/datasets/road'\n",
        "river_dir = '/content/aicup2024/datasets/river'\n",
        "\n",
        "if not os.path.exists(road_dir):\n",
        "    os.makedirs(road_dir)\n",
        "\n",
        "if not os.path.exists(river_dir):\n",
        "    os.makedirs(river_dir)\n",
        "\n",
        "for file in os.listdir(data_dir):\n",
        "\n",
        "    image_dir = os.path.join(data_dir, file)\n",
        "\n",
        "    \"\"\"\n",
        "    file.startswith(word)\n",
        "\n",
        "    若為訓練集 : word = 'TRA_RO'或'TRA_RI'\n",
        "    若為公開測試集 : word = 'PUB_RO'或'PUB_RI'\n",
        "    若為私有測試集 : word = 'PRI_RO'或'PRI_RI'\n",
        "    \"\"\"\n",
        "\n",
        "    if file.startswith('TRA_RO'):\n",
        "        shutil.copy(image_dir, road_dir)\n",
        "    elif file.startswith('TRA_RI'):\n",
        "        shutil.copy(image_dir, river_dir)"
      ],
      "metadata": {
        "id": "hdbExPlmMdsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 分割訓練集與驗證集"
      ],
      "metadata": {
        "id": "Gh22NTJKwEVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 分割訓練集與驗證集\n",
        "\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "random.seed(20)\n",
        "\n",
        "\"\"\"\n",
        "路徑說明\n",
        "data_dir 資料集所在路徑\n",
        "train_dir 訓練資料集要存放的路徑\n",
        "val_dir 驗證資料集要存放之路徑\n",
        "\"\"\"\n",
        "\n",
        "data_dir = '/content/aicup2024/datasets/road'\n",
        "\n",
        "#訓練資料集比例\n",
        "train_size = 0.8\n",
        "\n",
        "file_name = os.listdir(data_dir)\n",
        "random.shuffle(file_name)\n",
        "split = int(len(file_name) * train_size)\n",
        "\n",
        "train_file = file_name[:split]\n",
        "val_file = file_name[split:]\n",
        "\n",
        "train_dir = '/content/aicup2024/datasets/road/train'\n",
        "val_dir = '/content/aicup2024/datasets/road/val'\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "for name in train_file:\n",
        "    source = os.path.join(data_dir, name)\n",
        "    destination = os.path.join(train_dir, name)\n",
        "    shutil.move(source, destination)\n",
        "\n",
        "for name in val_file:\n",
        "    source = os.path.join(data_dir, name)\n",
        "    destination = os.path.join(val_dir, name)\n",
        "    shutil.move(source, destination)"
      ],
      "metadata": {
        "id": "WhxJ0ykeM5oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 檔案複製\n",
        "- 將已前處理完成的圖片複製到/aicup2024/datasets"
      ],
      "metadata": {
        "id": "m6dYqgNP1xjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 複製檔案\n",
        "# road\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 原始資料夾\n",
        "source_path = '/content/drive/MyDrive/2024_AICUP/datasets/road'\n",
        "\n",
        "# 目標資料夾\n",
        "target_path = '/content/aicup2024/datasets'\n",
        "\n",
        "if not os.path.exists(target_path):\n",
        "    os.makedirs(target_path)\n",
        "\n",
        "# 複製位置: target_path/file_name\n",
        "file_name = 'road'\n",
        "shutil.copytree(source_path, os.path.join(target_path, file_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6ntObN-G20kG",
        "outputId": "980d2d68-bc92-4875-8cf6-007c9b116a02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/aicup2024/datasets/road'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 複製檔案\n",
        "# river\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 原始資料夾\n",
        "source_path = '/content/drive/MyDrive/2024_AICUP/datasets/river'\n",
        "\n",
        "# 目標資料夾\n",
        "target_path = '/content/aicup2024/datasets'\n",
        "\n",
        "if not os.path.exists(target_path):\n",
        "    os.makedirs(target_path)\n",
        "\n",
        "# 複製位置: target_path/file_name\n",
        "file_name = 'river'\n",
        "shutil.copytree(source_path, os.path.join(target_path, file_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Bkq6IA6Q1ztJ",
        "outputId": "af547a13-a2c5-45f1-e274-eee334b7b9b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/aicup2024/datasets/river'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型訓練"
      ],
      "metadata": {
        "id": "T-jjrHCXMVsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### river模型訓練\n",
        "\n",
        "1. river_v9 以lr = 0.0001, lambda_L1 = 110 進行訓練，最終取用100_net.pth進行第二輪訓練\n",
        "2. river_v9_fine_v1 以lr = 0.0001, lambda_L1 = 110, river_v9->100_net.pth進行訓練, 最終取用30_net.pth進行下一輪訓練\n",
        "3. river_v9_fine_v2 以lr = 0.0001進行線性衰減， lambda_L1 = 100, river_v9_fine_v1->30_net.pth進行訓練，最終採用90_net.pth進行測試\n",
        "\n",
        "- 其餘參數參照程式碼設定"
      ],
      "metadata": {
        "id": "Dn7nW9ZS1ujP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 運行至100epoch結束後手動停止\n",
        "\n",
        "! python train.py --dataroot ./datasets/river --name river_v9 --model pix2pix --direction AtoB --preprocess none --load_size 512 --norm batch --lr 0.0001 --netG unet_512 --lambda_L1 110.0"
      ],
      "metadata": {
        "id": "u8v1ZIAM2cMj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3423eed5-7826-4390-8053-2dfd1e976755"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/river              \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "                direction: AtoB                          \n",
            "              display_env: main                          \n",
            "             display_freq: 400                           \n",
            "               display_id: 1                             \n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: vanilla                       \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                lambda_L1: 110.0                         \t[default: 100.0]\n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 512                           \t[default: 286]\n",
            "                       lr: 0.0001                        \t[default: 0.0002]\n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \t[default: cycle_gan]\n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: river_v9                      \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: unet_512                      \t[default: unet_256]\n",
            "                      ngf: 64                            \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: batch                         \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 0                             \n",
            "               preprocess: none                          \t[default: resize_and_crop]\n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: False                         \n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "The number of training images = 1728\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 66.999 M\n",
            "[Network D] Total number of parameters : 2.769 M\n",
            "-----------------------------------------------\n",
            "Setting up a new session...\n",
            "Exception in user code:\n",
            "------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 203, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 791, in urlopen\n",
            "    response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 497, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 395, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 243, in connect\n",
            "    self.sock = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 218, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7a2ef6a81f00>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 486, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 845, in urlopen\n",
            "    retries = retries.increment(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 515, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7a2ef6a81f00>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/visdom/__init__.py\", line 756, in _send\n",
            "    return self._handle_post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/visdom/__init__.py\", line 720, in _handle_post\n",
            "    r = self.session.post(url, data=data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 637, in post\n",
            "    return self.request(\"POST\", url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 519, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7a2ef6a81f00>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "\n",
            "\n",
            "Could not connect to Visdom server. \n",
            " Trying to start a server....\n",
            "Command: /usr/bin/python3 -m visdom.server -p 8097 &>/dev/null &\n",
            "create web directory ./checkpoints/river_v9/web...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "[Errno 99] Cannot assign requested address\n",
            "Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "(epoch: 1, iters: 100, time: 0.228, data: 0.335) G_GAN: 1.511 G_L1: 18.670 D_real: 0.191 D_fake: 0.582 \n",
            "(epoch: 1, iters: 200, time: 0.208, data: 0.003) G_GAN: 0.878 G_L1: 8.027 D_real: 0.911 D_fake: 0.674 \n",
            "(epoch: 1, iters: 300, time: 0.246, data: 0.014) G_GAN: 1.362 G_L1: 16.853 D_real: 0.368 D_fake: 0.324 \n",
            "(epoch: 1, iters: 400, time: 0.614, data: 0.011) G_GAN: 0.784 G_L1: 11.863 D_real: 0.828 D_fake: 0.249 \n",
            "(epoch: 1, iters: 500, time: 0.242, data: 0.004) G_GAN: 1.058 G_L1: 22.410 D_real: 0.087 D_fake: 1.056 \n",
            "(epoch: 1, iters: 600, time: 0.248, data: 0.013) G_GAN: 1.891 G_L1: 21.570 D_real: 0.097 D_fake: 0.274 \n",
            "(epoch: 1, iters: 700, time: 0.256, data: 0.004) G_GAN: 1.970 G_L1: 11.301 D_real: 0.381 D_fake: 0.118 \n",
            "(epoch: 1, iters: 800, time: 0.413, data: 0.011) G_GAN: 1.519 G_L1: 31.102 D_real: 0.131 D_fake: 1.035 \n",
            "(epoch: 1, iters: 900, time: 0.237, data: 0.013) G_GAN: 2.005 G_L1: 16.678 D_real: 0.124 D_fake: 0.364 \n",
            "(epoch: 1, iters: 1000, time: 0.240, data: 0.005) G_GAN: 1.585 G_L1: 17.186 D_real: 0.164 D_fake: 0.344 \n",
            "(epoch: 1, iters: 1100, time: 0.262, data: 0.004) G_GAN: 1.435 G_L1: 12.626 D_real: 0.700 D_fake: 0.114 \n",
            "(epoch: 1, iters: 1200, time: 0.464, data: 0.013) G_GAN: 2.073 G_L1: 14.393 D_real: 0.536 D_fake: 0.117 \n",
            "(epoch: 1, iters: 1300, time: 0.258, data: 0.010) G_GAN: 1.795 G_L1: 16.639 D_real: 0.370 D_fake: 0.218 \n",
            "(epoch: 1, iters: 1400, time: 0.262, data: 0.007) G_GAN: 1.116 G_L1: 17.795 D_real: 0.054 D_fake: 1.074 \n",
            "(epoch: 1, iters: 1500, time: 0.254, data: 0.004) G_GAN: 2.269 G_L1: 18.551 D_real: 0.079 D_fake: 0.375 \n",
            "(epoch: 1, iters: 1600, time: 0.454, data: 0.004) G_GAN: 2.371 G_L1: 17.005 D_real: 0.115 D_fake: 0.244 \n",
            "(epoch: 1, iters: 1700, time: 0.261, data: 0.013) G_GAN: 1.113 G_L1: 12.531 D_real: 0.747 D_fake: 0.327 \n",
            "End of epoch 1 / 200 \t Time Taken: 256 sec\n",
            "learning rate 0.0001000 -> 0.0001000\n",
            "(epoch: 2, iters: 72, time: 0.246, data: 0.015) G_GAN: 2.596 G_L1: 18.403 D_real: 0.175 D_fake: 0.099 \n",
            "(epoch: 2, iters: 172, time: 0.249, data: 0.015) G_GAN: 1.377 G_L1: 31.643 D_real: 0.017 D_fake: 0.427 \n",
            "(epoch: 2, iters: 272, time: 0.550, data: 0.004) G_GAN: 1.192 G_L1: 18.731 D_real: 0.318 D_fake: 0.438 \n",
            "(epoch: 2, iters: 372, time: 0.263, data: 0.004) G_GAN: 2.318 G_L1: 19.947 D_real: 0.136 D_fake: 0.128 \n",
            "(epoch: 2, iters: 472, time: 0.268, data: 0.003) G_GAN: 1.393 G_L1: 18.243 D_real: 0.212 D_fake: 0.324 \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/aicup2024/train.py\", line 51, in <module>\n",
            "    model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
            "  File \"/content/aicup2024/models/pix2pix_model.py\", line 82, in set_input\n",
            "    self.real_A = input['A' if AtoB else 'B'].to(self.device)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 將river_v9的100_net_G.pth與100_net_D.pth(或是停在100epoch用latest_net)放入/checkpoints/river_v9_fine_v1\n",
        "# 使用上面river_v9的100_net.pth繼續訓練\n",
        "# 運行至30epoch結束後手動停止\n",
        "\n",
        "! python train.py --dataroot ./datasets/river --name river_v9_fine_v1 --model pix2pix --direction AtoB --preprocess none --load_size 512 --norm batch --lr 0.0001 --netG unet_512 --lambda_L1 110.0 --continue_train --epoch 100 --epoch_count 1"
      ],
      "metadata": {
        "id": "iAA5WWd43RVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 將river_v9的30_net_G.pth與30_net_D.pth(或是停在30epoch用latest_net)放入/checkpoints/river_v9_fine_v2\n",
        "# 使用上面river_v9_fine_v1的30_net.pth繼續訓練\n",
        "# 運行至90epoch結束後手動停止\n",
        "\n",
        "! python train.py --dataroot ./datasets/river --name river_v9_fine_v2 --model pix2pix --direction AtoB --preprocess none --load_size 512 --norm batch --lr 0.0001 --netG unet_512 --lambda_L1 100.0 --continue_train --epoch_count 1 --n_epochs 0 --n_epochs_decay 100"
      ],
      "metadata": {
        "id": "R-i0hCGJ2a2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### road模型訓練\n",
        "\n",
        "1. lambda_L1 = 115 訓練100個epoch\n",
        "2. 將lambda_L1調整成110，使用100_net.pth從epoch = 101開始再訓練，最終採用170_net.pth進行測試\n",
        "\n",
        "- 其餘參數設定如程式碼"
      ],
      "metadata": {
        "id": "Nk1Ekoj3zmH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# road_v12模型訓練\n",
        "\n",
        "# 運行至100epoch結束後手動停止\n",
        "\n",
        "! python train.py --dataroot ./datasets/road --name road_v12 --model pix2pix --direction AtoB --preprocess none --load_size 512 --norm batch --lr 0.00015 --netG unet_512 --lambda_L1 115.0 --n_epochs 50 --n_epochs_decay 150"
      ],
      "metadata": {
        "id": "DELEz_O1MYQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 運行至170epoch結束後手動停止\n",
        "\n",
        "! python train.py --dataroot ./datasets/road --name road_v12 --model pix2pix --direction AtoB --preprocess none --load_size 512 --norm batch --lr 0.00015 --netG unet_512 --lambda_L1 110.0 --n_epochs 50 --n_epochs_decay 150 --continue_train --epoch_count 101 --epoch 100"
      ],
      "metadata": {
        "id": "QMOv8h5N0q1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型驗證"
      ],
      "metadata": {
        "id": "a0MwQbvK6GWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 河流模型驗證"
      ],
      "metadata": {
        "id": "dQu_LV6i3TgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python test.py --dataroot ./datasets/river --name river_v9_fine_v2 --model pix2pix --direction AtoB --norm batch --load_size 512 --preprocess none --results_dir ./results/val_river_v9_fine_v2 --phase val --netG unet_512 --epoch 90"
      ],
      "metadata": {
        "id": "u3ybfEYI3MPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 道路模型驗證"
      ],
      "metadata": {
        "id": "AR_f2mTD3uHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python test.py --dataroot ./datasets/road --name road_v12 --model pix2pix --direction AtoB --norm batch --load_size 512 --preprocess none --results_dir ./results/val_road_v12 --phase val --netG unet_512 --epoch 170"
      ],
      "metadata": {
        "id": "JbjJamJU30L-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 生成圖片"
      ],
      "metadata": {
        "id": "n3fdavRr6Igy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 河流圖片生成"
      ],
      "metadata": {
        "id": "0m-Zb5S94LKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# public testing datasets\n",
        "\n",
        "! python test.py --dataroot ./datasets/river --name river_v9_fine_v2 --model test --direction AtoB --norm batch --load_size 512 --preprocess none --results_dir ./results/pub_river_v9_fine_v2 --phase test --netG unet_512 --epoch 90"
      ],
      "metadata": {
        "id": "9oZVELfK4OCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# private testing datasets\n",
        "\n",
        "! python test.py --dataroot ./datasets/pri_river --name river_v9_fine_v2 --model test --direction AtoB --norm batch --load_size 512 --preprocess none --results_dir ./results/pri_river_v9_fine_v2 --phase test --netG unet_512 --epoch 90"
      ],
      "metadata": {
        "id": "k1qSCeqS46sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 道路圖片生成"
      ],
      "metadata": {
        "id": "13J6MkA-4ORK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# public testing datasets\n",
        "\n",
        "! python test.py --dataroot ./datasets/road --name road_v12 --model test --netG unet_512 --direction AtoB --norm batch --load_size 512 --preprocess none --results_dir ./results/pub_road_v12 --epoch 170 --num_test 360"
      ],
      "metadata": {
        "id": "A34xzDVU4JU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# private testing datasets\n",
        "\n",
        "! python test.py --dataroot ./datasets/pri_road --name road_v12 --model test --netG unet_512 --direction AtoB --norm batch --load_size 512 --preprocess none --results_dir ./results/pri_road_v12 --epoch 170 --num_test 360"
      ],
      "metadata": {
        "id": "ijZ7msA74atG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 生成圖片還原大小\n",
        "\n",
        "- 由於訓練時做了前處理，改變了圖片大小，因此生成完後進行相對應還原處理"
      ],
      "metadata": {
        "id": "NShENV3W5bVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "競賽繳交規定為.jpg檔案，因此進行轉檔\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "\"\"\"\n",
        "路徑說明\n",
        "source_folder 要轉檔資料的所在路徑\n",
        "destination_folder 轉檔後存放的路徑\n",
        "\"\"\"\n",
        "# 定義來源資料夾和目標資料夾的路徑\n",
        "source_folder = '/content/drive/MyDrive/dataset_GAN/A_padding/river'\n",
        "destination_folder = '/content/drive/MyDrive/dataset_GAN/result/pri_river_v14_new'\n",
        "\n",
        "if not os.path.exists(destination_folder):\n",
        "    os.makedirs(destination_folder)\n",
        "\n",
        "for filename in os.listdir(source_folder):\n",
        "\n",
        "    \"\"\"\n",
        "    以下filename.endswith('_fake.png') and filename.startswith('PRI')\n",
        "    在針對公開測試集時，請改成filename.endswith('_fake.png') and filename.startswith('PUB')\n",
        "    \"\"\"\n",
        "\n",
        "    if filename.endswith('_fake.png') and filename.startswith('PRI'):\n",
        "        source_path = os.path.join(source_folder, filename)\n",
        "        destination_path = os.path.join(destination_folder, filename)\n",
        "\n",
        "        img = Image.open(source_path)\n",
        "        new_filename = filename[:-9] + '.jpg'\n",
        "        new_destination_path = os.path.join(destination_folder, new_filename)\n",
        "        img.convert('RGB').save(new_destination_path, 'JPEG')"
      ],
      "metadata": {
        "id": "KvxeTLyZ5pUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "進行去除填充部分與還原大小\n",
        "運行完成後得生成圖片最終結果\n",
        "\"\"\"\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def crop_image_to_original_size(padded_image_path, output_path, original_size, target_size=(512, 512)):\n",
        "    \"\"\"\n",
        "    從填充後的圖片中裁剪出原始大小的圖片\n",
        "    padded_image_path: 填充後圖片的路徑\n",
        "    output_path: 裁剪後圖片的保存路徑\n",
        "    original_size: 原始圖片的大小 (寬, 高)\n",
        "    target_size: 填充後的目標尺寸 (寬, 高)\n",
        "    \"\"\"\n",
        "    # 讀取填充後的圖片\n",
        "    padded_img = Image.open(padded_image_path)\n",
        "\n",
        "    # 計算比例並調整圖片大小\n",
        "    ratio = min(target_size[0] / original_size[0], target_size[1] / original_size[1])\n",
        "    new_size = (int(original_size[0] * ratio), int(original_size[1] * ratio))\n",
        "\n",
        "    # 計算填充的起始點\n",
        "    left = (target_size[0] - new_size[0]) // 2\n",
        "    top = (target_size[1] - new_size[1]) // 2\n",
        "    right = left + new_size[0]\n",
        "    bottom = top + new_size[1]\n",
        "\n",
        "    # 剪裁圖片\n",
        "    original_img = padded_img.crop((left, top, right, bottom))\n",
        "\n",
        "    # 按比例縮放回原始尺寸\n",
        "    original_img_resized = original_img.resize(original_size, Image.ANTIALIAS)\n",
        "\n",
        "    # 保存裁剪並調整尺寸後的圖片\n",
        "    original_img_resized.save(output_path)\n",
        "\n",
        "\"\"\"\n",
        "路徑說明\n",
        "padded_folder 存放要還原的填充圖片路徑\n",
        "output_folder 最終繳交檔案存放路徑\n",
        "\"\"\"\n",
        "\n",
        "original_size = (428, 240)  # 規定圖片大小\n",
        "padded_folder = ''\n",
        "output_folder = ''\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "for filename in os.listdir(padded_folder):\n",
        "    padded_image_path = os.path.join(padded_folder, filename)\n",
        "    output_image_path = os.path.join(output_folder, filename)\n",
        "    crop_image_to_original_size(padded_image_path, output_image_path, original_size)"
      ],
      "metadata": {
        "id": "mc8KoxH15uX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}